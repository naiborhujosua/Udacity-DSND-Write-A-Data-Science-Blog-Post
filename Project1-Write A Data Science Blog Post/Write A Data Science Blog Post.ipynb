{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Pick a dataset.\n",
    "I want to choose all of the [Stack Overflow Survey - Multiple Years](https://insights.stackoverflow.com/survey) results in this project.  \n",
    "I choose the year of the survey results as the file name and save them in the floder called 'data'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from showCharts import render_echarts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data in 2011 has   2813 rows, 65 columns\n",
      "data in 2012 has   6243 rows, 75 columns\n",
      "data in 2013 has   9742 rows,128 columns\n",
      "data in 2014 has   7643 rows,120 columns\n",
      "data in 2015 has  26086 rows,222 columns\n",
      "data in 2016 has  56030 rows, 66 columns\n",
      "data in 2017 has  51392 rows,154 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib \n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# dict for original data\n",
    "org_datas = {}\n",
    "for year in range(2011,2019,1):\n",
    "    if year in [2016,2017]:\n",
    "        org_datas[year] = pd.read_csv('data/%s.csv' %year, encoding = 'ISO-8859-1',low_memory=False)\n",
    "    elif year == 2018:\n",
    "        org_datas[year] = pd.read_excel('data/%s.xlsx' %year, encoding = 'ISO-8859-1')\n",
    "    elif year == 2015:\n",
    "        org_datas[year] = pd.read_csv('data/%s.csv' %year, encoding = 'ISO-8859-1',header=[1],low_memory=False)\n",
    "    else:\n",
    "        org_datas[year] = pd.read_csv('data/%s.csv' %year, encoding = 'ISO-8859-1',header=[0,1],low_memory=False)\n",
    "    print(\"data in %4d has %6d rows,%3d columns\" %(year,org_datas[year].shape[0],org_datas[year].shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2  Pose at least three questions related to business or real-world applications of how the data could be used.\n",
    "\n",
    "- 1.Which languages were most popular in each year?  \n",
    "- 2.Which occupations were most popular in each year?  \n",
    "- 3.What is the average IT_experience of programmers in different countries each year?  \n",
    "- 4.What is the average age of programmers in different countries each year?  \n",
    "- 5.What is the average salary of the participants in different countries each year?  \n",
    "- 6.What is the average salary of the participants in different countries each year?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Prepare data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change data_column_names \n",
    "def change_column_name(df):\n",
    "    new_columns = []\n",
    "    for index,tuple_value in enumerate(list(df.columns)):\n",
    "        if index >= 1:\n",
    "            if \"Unnamed\" in tuple_value[0]:\n",
    "                tuple_value = (new_columns[index-1][0],tuple_value[1])\n",
    "        new_columns.append(tuple_value)\n",
    "    df.columns = pd.MultiIndex.from_tuples(new_columns)\n",
    "    return df\n",
    "\n",
    "def change_multiindex_to_simpleindex(df):\n",
    "    df.columns = ['-'.join(i) if type(i) == tuple else i for i in list(df.columns)]\n",
    "\n",
    "for i in [2011,2012,2013,2014]:\n",
    "    org_datas[i] = change_column_name(org_datas[i])\n",
    "    \n",
    "print(\"successed to change the column's names of dfs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Gather necessary data to answer your questions\n",
    " \n",
    "**select the following columns in which I am interested in**\n",
    "- Country\n",
    "- age\n",
    "- IT/Programming experience\n",
    "- industry\n",
    "- size of company\n",
    "- occupation\n",
    "- languages\n",
    "- salary\n",
    "\n",
    "**merge all of the annual datas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from merge_data import merge_annual_datas\n",
    "all_years_data = merge_annual_datas(org_datas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take a look at the summary statistics associated with the quantitative variables in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_years_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Data Process  \n",
    "Handle categorical and missing data\n",
    "- show the data types of all the df's columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_df = deepcopy(all_years_data)\n",
    "handle_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to year column, all other columns need to be handled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Handle categorica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1.See all of the values in column **'country'** and modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_df.country.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some countries are repeated,such as 'United States' and 'United States of America'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_df.loc[handle_df.country == 'United States',['country']] = \"United States of America\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2.See all of the values in column **'IT/Programming experience'** and modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_df['IT_experience'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some values like '41070','40944','41435','41310' are hard for me to understand their means.So I decide to mark them as 'nan'  \n",
    "Some values like ''6/10/2013',I guess it's mean is '6-10 years in 2013'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_IT(handle_df):\n",
    "    handle_df.loc[handle_df['IT_experience'].isin(['41070','40944','41435','41310']),['IT_experience']]=np.NaN\n",
    "    handle_df.loc[handle_df['IT_experience'] == '6/10/2013' ,['IT_experience']]='6-10'\n",
    "    handle_df.loc[handle_df['IT_experience'] == '2/5/2013' ,['IT_experience']]='2-5'\n",
    "    handle_df.loc[handle_df['IT_experience'] == '2/5/2014' ,['IT_experience']]='2-5'\n",
    "    handle_df.loc[handle_df['IT_experience'] == '6/10/2014' ,['IT_experience']]='6-10'\n",
    "    handle_df.loc[handle_df['IT_experience'] == 'Less than a year' ,['IT_experience']]='1'\n",
    "    handle_df['IT_experience'] = handle_df['IT_experience'].map(lambda x:str(x).replace(\" to \",'-'))\n",
    "    return handle_df\n",
    "handle_df = handle_IT(handle_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**change the type of the column to 'int':**  \n",
    "If the format of the value contains \"<\", \">\",\"older\" or \"under\", retain the number only.  \n",
    "If the format of the value is age range,change it to the midpoint of the age range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_range(df,feature,dropna=True):\n",
    "    \n",
    "    from copy import deepcopy\n",
    "    \n",
    "    df = deepcopy(df)\n",
    "    # remove vocabulary ,\"<\",\">\"\n",
    "    remove = lambda x: \"\".join([i for i in str(x) if i in [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"-\",'.']])\n",
    "    df[feature] = df[feature].map(remove)\n",
    "\n",
    "\n",
    "    # if age range ,change it to the midpoint\n",
    "    # for na value,I mark them as 'NaN'\n",
    "    change_to_midpoint = lambda x: np.average([float(i) for i in x.split(\"-\")]) if \"-\" in x else np.NaN if x == \"\" else float(x)\n",
    "    df[feature] = df[feature].map(change_to_midpoint)\n",
    "\n",
    "    if dropna:\n",
    "        # remove \"\"\n",
    "        df = df[df[feature] != -1]\n",
    "\n",
    "    if feature in df.select_dtypes(include=['float','int']).columns:\n",
    "        print(\"successed to modify the column '%s'.\" %feature)\n",
    "    else:\n",
    "        print(\"failed to modify the column '%s'.\" %feature)\n",
    "    return df\n",
    "handle_df = process_data_range(handle_df,'IT_experience',dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.See all of the values in column **'occupation'** and modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(handle_df['occupation'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of this column is case sensitive.For example,the word 'Back_end web developer' and the word 'Back_End Web Developer' are the same.To avoid recounting them, I convert all values to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_df.loc[:,'occupation'] = handle_df['occupation'].map(lambda x:str(x).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.See all of the values in column **'industry'** and modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_df['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of this column is normal, I think they do not need to be handled."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.See all of the values in column **'size of company'** and modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_df['company_size'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_df.loc[handle_df['company_size'].isin(['I prefer not to answer',\"I don't know\"]),['company_size']]=np.NaN\n",
    "handle_df.loc[handle_df['company_size'] == 'Fortune 1000 (1,000+)' ,['company_size']]='1000'\n",
    "handle_df.loc[handle_df['company_size'] == '1/25/2013' ,['company_size']]='1-25'\n",
    "handle_df.loc[handle_df['company_size'] == '1/5/2014' ,['company_size']]='1-5'\n",
    "handle_df.loc[handle_df['company_size'] == '6/15/2014' ,['company_size']]='6-15'\n",
    "# I guess they are likely to be working alone,so I mark them as '1'.\n",
    "handle_df.loc[handle_df['company_size'].isin(['Student',\"Other (not working, consultant, etc.)\"]),['company_size']]='1'\n",
    "\n",
    "handle_df['company_size'] = handle_df['company_size'].map(lambda x:str(x).replace(\" to \",'-'))\n",
    "\n",
    "handle_df = process_data_range(handle_df,'company_size',dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_df['company_size'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.See all of the values in column **'age'** and modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_df.age.value_counts()\n",
    "handle_df = process_data_range(handle_df,'age',dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_df.age.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7.See all of the values in column **'salary'** and modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_df['salary'].value_counts()\n",
    "handle_df = process_data_range(handle_df,'salary',dropna=False)\n",
    "handle_df['salary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 drop outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Drop top 2% and last 2% of the values in 'salary' colmns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(df, parse_column_name=None,output='df',drop_percent=2):\n",
    "    '''find outliers\n",
    "    \n",
    "    parameters\n",
    "    -------------------\n",
    "    parse_column_name: str\n",
    "    output: {\"df\",\"index\"}\n",
    "    drop_percent: int or float\n",
    "    \n",
    "    '''\n",
    "#     Q1 = np.percentile(df[parse_column_name],25)\n",
    "#     Q3 = np.percentile(df[parse_column_name],75)\n",
    "#     step = 1.5 * (Q3 - Q1)\n",
    "    \n",
    "    # 显示异常点\n",
    "    indexes = ~((df[parse_column_name] >= np.percentile(df[parse_column_name],drop_percent)) & \n",
    "                (df[parse_column_name] <=  np.percentile(df[parse_column_name],100-drop_percent)))\n",
    "    outlier_data = df[indexes]\n",
    "    print(\"Data points considered outliers for the feature '{}':\".format(parse_column_name))\n",
    "    print(\"It has %d outliers\" %(len(outlier_data)))\n",
    "    if output=='df':\n",
    "        display(outlier_data)\n",
    "        return outlier_data\n",
    "    elif output=='index':\n",
    "        return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_years_data_drop_outliers = deepcopy(handle_df)\n",
    "all_years_data_drop_outliers.dropna(subset=['salary'],inplace=True)\n",
    "all_years_data_drop_outliers= all_years_data_drop_outliers[~find_outliers(all_years_data_drop_outliers,parse_column_name='salary',\n",
    "                                                                    output='index',drop_percent=2)]\n",
    "print(f'After dropped missing values and outliers in \"salary\", data has {all_years_data_drop_outliers.shape[0]} samples {all_years_data_drop_outliers.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Analyze and Visualize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "**1**.Which languages were most popular in each year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyecharts import Timeline\n",
    "\n",
    "data_analyze = deepcopy(all_years_data_drop_outliers)\n",
    "\n",
    "possible_vals = ['JavaScript','SQL','Java','C#','Python','PHP','CSS','HTML','C++','C','Bash/Shell','Ruby','TypeScript','Objective-C',\n",
    " 'Server','Node.js','Swift','AngularJS','Visual','Basic','Go','R','Matlab',]\n",
    "\n",
    "def total_count(df, col1, col2, look_for=None):\n",
    "    '''\n",
    "    INPUT:\n",
    "    df - the pandas dataframe you want to search\n",
    "    col1 - the column name you want to look through\n",
    "    col2 - the column you want to count values from\n",
    "    look_for - a list of strings you want to search for in each row of df[col];\n",
    "    \n",
    "    OUTPUT:\n",
    "    new_df - a dataframe of each look_for with the count of how often it shows up\n",
    "    '''\n",
    "    \n",
    "    from collections import defaultdict\n",
    "    new_df = defaultdict(int)\n",
    "    #loop through list of ed types\n",
    "    for val in look_for:\n",
    "        #loop through rows\n",
    "        for idx in range(df.shape[0]):\n",
    "            #if the ed type is in the row add 1\n",
    "            if val in df[col1][idx]:\n",
    "                new_df[val] += int(df[col2][idx])\n",
    "    new_df = pd.DataFrame(pd.Series(new_df)).reset_index()\n",
    "    new_df.columns = [col1, col2]\n",
    "    new_df.sort_values('count', ascending=False, inplace=True)\n",
    "    return new_df\n",
    "\n",
    "def clean_and_plot(df, title, feature, possible_vals, plot=True):\n",
    "    '''\n",
    "    INPUT \n",
    "        df - a dataframe holding the languages column\n",
    "        title - string the title of your plot\n",
    "        plot - bool providing whether or not you want a plot back\n",
    "        feature - \n",
    "        \n",
    "    OUTPUT\n",
    "        study_df - a dataframe with the count of how many individuals\n",
    "        Displays a plot of pretty things related to the CousinEducation column.\n",
    "    '''\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    study = df[feature].value_counts().reset_index()\n",
    "    study.rename(columns={'index': feature, feature: 'count'}, inplace=True)\n",
    "    study_df = total_count(study, feature, 'count', possible_vals)\n",
    "\n",
    "    study_df.set_index(feature, inplace=True)\n",
    "    if plot:\n",
    "        (study_df/study_df.sum()).plot(kind='bar', legend=None);\n",
    "        plt.title(title);\n",
    "        plt.show()\n",
    "    props_study_df = study_df/study_df.sum()\n",
    "    return props_study_df\n",
    "\n",
    "# def show_most_popular_languages(df,year,num_language = 3):\n",
    "#     '''\n",
    "#     INPUT\n",
    "#         df - a dataframe holding the languages and count\n",
    "#         year - which year\n",
    "#         num_language - show the Top 'num_language' most popular languages\n",
    "    \n",
    "#     OUTPUT\n",
    "#         top_n_languages - the Top 'num_language' most popular languages\n",
    "#     '''\n",
    "#     df = df.sort_values(by='count',ascending=False)\n",
    "#     df.reset_index(inplace=True)\n",
    "    \n",
    "#     top_n_languages = list(df.languages)[:num_language]\n",
    "    \n",
    "#     print(\"The Top %d most popular languages in %d is \\n%s\" %(num_language,year,\",\".join(top_n_languages)))\n",
    "#     print(\"-\"* 60)\n",
    "    \n",
    "#     return top_n_languages\n",
    "    \n",
    "rank_years = {}\n",
    "language_counts_df = {}\n",
    "\n",
    "q1_timeline = Timeline(is_auto_play=True, timeline_bottom=0)\n",
    "for year in range(2011,2019):\n",
    "    cur_data = data_analyze[data_analyze.year == year]\n",
    "    cur_language_counts_df = clean_and_plot(cur_data,title = \"Popular languages in %d\" %year, feature='languages', \n",
    "                                            possible_vals=possible_vals,plot=False)\n",
    "    \n",
    "    # reserve top 10 languages\n",
    "    cur_language_counts_df = cur_language_counts_df.head(10)\n",
    "    cur_language_counts_df.loc['Other',:] = 1 - cur_language_counts_df.sum().sum()\n",
    "    \n",
    "    # change the value to percent\n",
    "    cur_language_counts_df = cur_language_counts_df.applymap(lambda x:round(x*100,2) if x > 0 else 0)\n",
    "    \n",
    "    cur_chart = render_echarts(cur_language_counts_df,chart_title=\"The top 10 popular languages in each year\",\n",
    "              chart_kind='pie',\n",
    "                          legend_pos='90%',legend_orient='vertical',legend_top='center',\n",
    "                          is_toolbox_show=False,\n",
    "                          is_label_show=True,label_formatter='{b}\\n{c}%',\n",
    "                          rosetype=\"radius\",)\n",
    "    \n",
    "    q1_timeline.add(cur_chart,year)\n",
    "#     rank_years[year]=show_most_popular_languages(cur_language_counts_df,year,num_language=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to question 1**:  \n",
    "C is the most popular language among participants in 2011,2012.In the next 5 years, the number of people participating in the survey using Java exceeded C, Java becames the most popular language.But in 2018, C is the most popular language again among participants ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "**2**.Which occupations were most popular in each year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_vals = ['full-stack web developer',\n",
    " 'back-end developer',\n",
    " 'full-stack developer',\n",
    " 'front-end developer',\n",
    " 'back-end web developer',\n",
    " 'student',\n",
    " 'desktop or enterprise applications developer',\n",
    " 'mobile developer',\n",
    " 'database administrator',\n",
    " 'system administrator',\n",
    " 'front-end web developer',\n",
    " 'devops specialist',\n",
    " 'designer',\n",
    " 'desktop developer',\n",
    " 'mobile dev (android, ios, wp & multi-platform)',\n",
    " 'data or business analyst',\n",
    " 'qa or test developer',\n",
    " 'web application developer',\n",
    " 'data scientist or machine learning specialist',\n",
    " 'data scientist',\n",
    " 'full stack web developer',\n",
    " 'engineering manager',\n",
    " 'embedded application developer',\n",
    " 'product manager',\n",
    " 'embedded applications or devices developer',\n",
    " 'mathematics developers (data scientists, machine learning devs & devs with stats & math backgrounds)']\n",
    "\n",
    "rank_years = {}\n",
    "occupation_counts_df = {}\n",
    "\n",
    "q2_timeline = Timeline(is_auto_play=True, timeline_bottom=0)\n",
    "for year in range(2011,2019):\n",
    "    cur_data = data_analyze[data_analyze.year == year]\n",
    "    cur_occupation_counts_df = clean_and_plot(cur_data,title = \"Popular occupations in %d\" %year,feature = 'occupation',\n",
    "                                              possible_vals=possible_vals,plot=False)\n",
    "    \n",
    "    # reserve top 10 occupations\n",
    "    cur_occupation_counts_df = cur_occupation_counts_df.head(10)\n",
    "    cur_occupation_counts_df.loc['Other',:] = 1 - cur_occupation_counts_df.sum().sum()\n",
    "    \n",
    "    # change the value to percent\n",
    "    cur_occupation_counts_df = cur_occupation_counts_df.applymap(lambda x:round(x*100,2) if x > 0 else 0)\n",
    "    \n",
    "    cur_chart = render_echarts(cur_occupation_counts_df,chart_title=\"The top 10 popular occupations in each year\",\n",
    "              chart_kind='pie',\n",
    "                          legend_pos='90%',legend_orient='vertical',legend_top='center',\n",
    "                          is_toolbox_show=False,\n",
    "                          is_label_show=True,label_formatter='{b}\\n{c}%',\n",
    "                          rosetype=\"radius\",)\n",
    "    \n",
    "    q2_timeline.add(cur_chart,year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2_timeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to question 2**:  \n",
    "- Web application developer is the most popular occupation among participants before 2012.\n",
    "- Full-stack web developer is the most popular occupation among participants between 2013 and 2017.\n",
    "- back-end developer is the most popular occupation among participants after 2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "**3**.What is the average IT_experience of programmers in different countries each year?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First,I just want to see the top 10 countries with the largest number of the participants who take part in these surveys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see the top 10 countries with the largest number of the participants who take part in these surveys\n",
    "top_10_countries = list(data_analyze.groupby('country').count() \\\n",
    "    .sort_values(by='index',ascending=False).head(10).index)\n",
    "\n",
    "print(\"Top 10 counties are %s\" %\",\".join(top_10_countries))\n",
    "\n",
    "#In addition, I also want to see the infomation of China's participants\n",
    "top_10_countries.append('China')\n",
    "top_10_countries_and_China = top_10_countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_information_in_interest_countries_each_year(df, feature,countries):\n",
    "    # drop missing value in columns 'IT_experience' and 'country'\n",
    "    df = df.dropna(subset=[feature,'country'])\n",
    "    df = df[df.country.isin(top_10_countries_and_China)]\n",
    "    average_df = pd.pivot_table(df,index='year',values=feature,columns='country',aggfunc=np.average,\n",
    "                                                              margins='row')\n",
    "    average_df.drop(index=['All'],inplace=True)\n",
    "    average_df.rename(columns={'All':'Average'},inplace=True)\n",
    "    average_df.dropna(how='all',inplace=True)\n",
    "\n",
    "    # round df's values for showing beautiful\n",
    "    average_df = average_df.applymap(lambda x:round(x,2) if x > 0 else x)\n",
    "    \n",
    "    return average_df\n",
    "\n",
    "average_IT_experience_country_year_table = average_information_in_interest_countries_each_year(data_analyze,'IT_experience',\n",
    "                                                                                              top_10_countries_and_China)\n",
    "\n",
    "display(average_IT_experience_country_year_table)\n",
    "q3_chart = render_echarts(average_IT_experience_country_year_table,chart_title=\"The average IT_experiences of programmers in different countries each year\",\n",
    "              chart_kind='line',\n",
    "                          legend_pos='88%',legend_orient='vertical',legend_top='center',\n",
    "                          is_toolbox_show=False,height=800,\n",
    "                          yaxis_min=2)\n",
    "q3_chart "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to question 3**:  \n",
    "There are two main features in this graph.  \n",
    "\n",
    "- Firstly, the average IT work experience of programmers in developed countries is very close,and all of them is more than 6 years.Otherwise,the average IT work experience of programmers in developing countries is at a low level, most of which are below 6 \n",
    "\n",
    "- In addition, the average ages of programmers in all countries show an decrease during 2011-2015.I guess the reason is there was a large amount of graduates enter in the IT market at that time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "**4**.What is the average age of programmers in different countries each year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "average_age_country_year_table = average_information_in_interest_countries_each_year(data_analyze,'age',\n",
    "                                                                                              top_10_countries_and_China)\n",
    "\n",
    "q4_chart = render_echarts(average_age_country_year_table,chart_title=\"The average ages of programmers in different countries each year\",\n",
    "              chart_kind='line',\n",
    "                          legend_pos='88%',legend_orient='vertical',legend_top='center',\n",
    "                          is_toolbox_show=False,\n",
    "                          is_label_show=True,label_formatter='{a}\\n{c}',height=800,\n",
    "                          yaxis_min = 25)\n",
    "q4_chart "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to question 4**:  \n",
    "There are two main features in this graph.  \n",
    "- Firstly, it’s obvious that the programmers in developing counties are younger than their counterparts in developed countries during the whole period.   \n",
    "- In addition, the average ages of programmers in all countries show an increase during 2016-2018."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "**5**.What is the average salary of the participants in different countries each year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_salary_country_year_table = average_information_in_interest_countries_each_year(data_analyze,'salary',top_10_countries_and_China)\n",
    "\n",
    "# round data for showing beautiful\n",
    "average_salary_country_year_table = average_salary_country_year_table.applymap(lambda x:round(x,2) if x > 0 else x)\n",
    "q5_chart = render_echarts(average_salary_country_year_table,chart_title=\"The average salaries of programmers in different countries each year\",\n",
    "              chart_kind='line',\n",
    "                          legend_pos='88%',legend_orient='vertical',legend_top='center',\n",
    "                          is_toolbox_show=False,\n",
    "                          is_label_show=True,label_formatter='{a}\\n{c}',height=800,\n",
    "                          yaxis_min = 10000)\n",
    "q5_chart "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to question 5**:  \n",
    "- It’s obvious that the programmers in developing counties learn less salary than their counterparts in developed countries during the whole period. The top three countries where programmers make the most salary are the United States,Australia,Canada.\n",
    "- Over the five years after 2011, the average salary of programmers dropped by around 24%.It rose by 24% between 2016 and 2018.\n",
    "- In many countries, programmers' annual salary has risen in different degrees between 2016 and 2018, except for Poland, China, United Kingdom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "**6**.What is the average salary of the participants in different countries each year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "average_age_country_year_table = average_information_in_interest_countries_each_year(data_analyze,'company_size',\n",
    "                                                                                              top_10_countries_and_China)\n",
    "\n",
    "q6_chart = render_echarts(average_age_country_year_table,chart_title=\"The average size of companies in different countries each year\",\n",
    "              chart_kind='line',\n",
    "                          legend_pos='88%',legend_orient='vertical',legend_top='center',\n",
    "                          is_toolbox_show=False,\n",
    "                          is_label_show=True,label_formatter='{a}\\n{c}',height=800,\n",
    "                          yaxis_min = 25)\n",
    "q6_chart "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Model \n",
    "Create a model to perdict the salary of a programmer if I have his some features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Drop missing or impute before modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop_missing_value = deepcopy(data_analyze)\n",
    "del data_drop_missing_value['index']\n",
    "# see the numbers of missing value in each column\n",
    "data_drop_missing_value.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- columns 'age','salary','industry','company_size' have large proportion of missing values.I should drop them after consideration.  \n",
    "- Other columns can be simply dropna.\n",
    "  \n",
    "  \n",
    "**Drop the row if it has null value in columns 'country','IT_experience','languages ','occupation'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_drop_missing_value = data_drop_missing_value.dropna(subset=['country','IT_experience','languages','occupation'],how='any')\n",
    "print(f'After dropped missing value in \"country\",\"IT_experience\",\"languages\",\"occupation\", data has {data_drop_missing_value.shape[0]} samples {data_drop_missing_value.shape[1]} columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Value in column 'Industry'**\n",
    "- Because it has large proportion of missing value.If I simply drop missing value in column 'Industry',it will loss lots of samples.\n",
    "- So I decide to divide the df into two groups.One has missing value and the other hasn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop_missing_value['industry_is_na'] = pd.isna(data_drop_missing_value.industry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.pivot_table(data_drop_missing_value.dropna(subset=['age','IT_experience','company_size']),columns='industry_is_na',\n",
    "               values=['salary','age','IT_experience',\"company_size\"],aggfunc=np.average,dropna=True))\n",
    "\n",
    "del data_drop_missing_value['industry_is_na']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are large differences between the two groups above.It’s not wise to remove missing data directly.So I decide to use 'missing' to replace missing value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop_missing_value.loc[:,'industry'] = data_drop_missing_value['industry'].map(lambda x: \"missing\" if pd.isna(x) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Missing Value in column 'size of company'**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the proportion of missing value in 'company_size' column\n",
    "pro_company_size = data_drop_missing_value.company_size.isnull().mean()\n",
    "print('\"company_size\" column has %d%% missing values' %(pro_company_size*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has a large proportion missing values,so I decided to drop this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_drop_missing_value['company_size']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Create A Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "# from sklearn.preprocessing import StandardScaler,normalize\n",
    "# from sklearn.pipeline import Pipeline\n",
    "\n",
    "is_use_PCA = True\n",
    "\n",
    "model_df = all_years_data_drop[['country','IT_experience', 'age', 'industry','year','salary']]\n",
    "\n",
    "# Fill numeric columns with the mean\n",
    "num_vars = model_df.select_dtypes(include=['float', 'int']).columns\n",
    "for col in num_vars:\n",
    "    model_df[col].fillna((model_df[col].mean()), inplace=True)\n",
    "\n",
    "# Dummy the categorical variables\n",
    "cat_vars = model_df.select_dtypes(include=['object']).copy().columns\n",
    "for var in  cat_vars:\n",
    "    # for each cat add dummy var, drop original column\n",
    "    model_df = pd.concat([model_df.drop(var, axis=1), pd.get_dummies(model_df[var], prefix=var, prefix_sep='_', drop_first=True)], axis=1)\n",
    "    \n",
    "#Split into explanatory and response variables\n",
    "X = model_df.drop(columns=['salary'])\n",
    "y = model_df['salary']\n",
    "\n",
    "#Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state=42) \n",
    "\n",
    "lm_model = DecisionTreeRegressor() # Instantiate\n",
    "lm_model.fit(X_train, y_train) #Fit\n",
    "\n",
    "#Predict and score the model\n",
    "y_test_preds = lm_model.predict(X_test) \n",
    "print(\"The r-squared score for the model was {} on {} values.\".format(r2_score(y_test, y_test_preds), len(y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
